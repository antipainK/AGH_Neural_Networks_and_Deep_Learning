{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import mkl\n",
    "\n",
    "mkl.set_num_threads(2)\n",
    "np.random.seed(1234)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handy utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_ones(matrix, axis=1):\n",
    "    return np.concatenate((matrix, np.ones((matrix.shape[0], 1), dtype=np.float32)), axis=axis)\n",
    "\n",
    "def zeros(*dims):\n",
    "    return np.zeros(shape=tuple(dims), dtype=np.float32)\n",
    "\n",
    "def ones(*dims):\n",
    "    return np.ones(shape=tuple(dims), dtype=np.float32)\n",
    "\n",
    "def rand(*dims):\n",
    "    return np.random.rand(*dims).astype(np.float32)\n",
    "\n",
    "def randn(*dims):\n",
    "    return np.random.randn(*dims).astype(np.float32)\n",
    "\n",
    "def chunks(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def as_matrix(vector):\n",
    "    return np.reshape(vector, (-1, 1))\n",
    "\n",
    "def tiles(examples):\n",
    "    rows_count = examples.shape[0]\n",
    "    cols_count = examples.shape[1]\n",
    "    tile_height = examples.shape[2]\n",
    "    tile_width = examples.shape[3]\n",
    "    \n",
    "    space_between_tiles = 2\n",
    "    img_matrix = np.empty(shape=(rows_count * (tile_height + space_between_tiles) - space_between_tiles,  \n",
    "                                 cols_count * (tile_width + space_between_tiles) - space_between_tiles))\n",
    "    img_matrix.fill(np.nan)\n",
    "\n",
    "    for r in range(rows_count):\n",
    "        for c in range(cols_count):\n",
    "            x_0 = r * (tile_height + space_between_tiles)\n",
    "            y_0 = c * (tile_width + space_between_tiles)\n",
    "            ex_min = np.min(examples[r, c])\n",
    "            ex_max = np.max(examples[r, c])\n",
    "            img_matrix[x_0:x_0 + tile_height, y_0:y_0 + tile_width] = (examples[r, c] - ex_min) / (ex_max - ex_min)\n",
    "    \n",
    "    plt.matshow(img_matrix, cmap='gray', interpolation='none')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def draw_rbm_filters(rbm):\n",
    "    filters = np.reshape(np.transpose(rbm.W)[:-1, :-1], newshape=(8, -1, 28, 28))\n",
    "    tiles(filters)\n",
    "\n",
    "def draw_layer_filters(layer):\n",
    "    filters = np.reshape(layer.W[:-1].T, newshape=(8, -1, 28, 28))\n",
    "    tiles(filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(batch, stochastic=False):\n",
    "    activations = 1.0 / (1.0 + np.exp(-batch))\n",
    "    if stochastic:\n",
    "        return activations > rand(*activations.shape).astype(np.float32)\n",
    "    else:\n",
    "        return activations\n",
    "\n",
    "def sigmoid_derivative(batch):\n",
    "    s = sigmoid(batch)\n",
    "    return s * (1.0 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(batch, stochastic=False):\n",
    "    raise Exception(\"Gaussian activation function is not implemented\")\n",
    "    \n",
    "    # return ???\n",
    "\n",
    "def gaussian_derivative(batch):\n",
    "    raise Exception(\"Derivative of the gaussian activation function is not implemented\")\n",
    "    \n",
    "    # return ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnist\n",
    "digits = np.reshape(mnist.train_images()[:12*24], newshape=(12, 24, 28, 28))\n",
    "tiles(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBM & DBN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Rbm:\n",
    "    def __init__(self, visible_size, hidden_size, visible_act_func, hidden_act_func, \n",
    "                 learning_rate, momentum, l2_penalty):\n",
    "        self.visible_size = visible_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.visible_act_func = visible_act_func\n",
    "        self.hidden_act_func = hidden_act_func\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.l2_penalty = l2_penalty\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.W = np.random.normal(scale=0.01, size=(self.visible_size+1, self.hidden_size+1)).astype(np.float32)\n",
    "        self.W[:, -1] = 0.0\n",
    "        self.W[-1, :] = 0.0\n",
    "        self.M = zeros(self.visible_size+1, self.hidden_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cdk(rbm, minibatch, k=1):\n",
    "    observations_count = minibatch.shape[0]\n",
    "\n",
    "    positive_visible = minibatch\n",
    "    negative_visible = append_ones(zeros(observations_count, rbm.visible_size))\n",
    "\n",
    "    positive_hidden = append_ones(zeros(observations_count, rbm.hidden_size))\n",
    "    negative_hidden = append_ones(zeros(observations_count, rbm.hidden_size))\n",
    "\n",
    "    z = minibatch @ rbm.W[:, :-1]\n",
    "    positive_hidden[:, :-1] = rbm.hidden_act_func(z)\n",
    "    negative_hidden[:, :-1] = rbm.hidden_act_func(z, stochastic=True)\n",
    "\n",
    "    for cd_i in range(k):\n",
    "        negative_visible[:, :-1] = rbm.visible_act_func(negative_hidden @ rbm.W[:-1, :].T,\n",
    "                                                        stochastic=True)\n",
    "        z = negative_visible @ rbm.W[:, :-1]\n",
    "        if cd_i < (k - 1):\n",
    "            negative_hidden[:, :-1] = rbm.hidden_act_func(z, stochastic=True)\n",
    "        else:\n",
    "            negative_hidden[:, :-1] = rbm.hidden_act_func(z)\n",
    "\n",
    "    rbm.M *= rbm.momentum\n",
    "    rbm.M += (rbm.learning_rate / observations_count) * positive_visible.T @ positive_hidden\n",
    "    rbm.M -= (rbm.learning_rate / observations_count) * negative_visible.T @ negative_hidden\n",
    "\n",
    "    if rbm.l2_penalty is not None:\n",
    "        rbm.M[:-1, :-1] = rbm.M[:-1, :-1] - rbm.learning_rate * rbm.l2_penalty * rbm.W[:-1, :-1]\n",
    "\n",
    "    rbm.W += rbm.M;\n",
    "    \n",
    "def reconstuction_error(rbm, minibatch):\n",
    "    observations_count = minibatch.shape[0]\n",
    "    visible = zeros(observations_count, rbm.visible_size)\n",
    "    hidden = append_ones(zeros(observations_count, rbm.hidden_size))\n",
    "    \n",
    "    hidden[:, :-1] = rbm.hidden_act_func(minibatch @ rbm.W[:, :-1])\n",
    "    hidden[:, :-1] = (hidden[:, :-1] > rand(observations_count, rbm.hidden_size))\n",
    "    \n",
    "    visible = rbm.visible_act_func(hidden @ np.transpose(rbm.W[:-1, :]))\n",
    "    \n",
    "    error = minibatch[:, :-1] - visible\n",
    "    error = np.sum(np.square(error)) / observations_count\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def propagate_up(dbn, layers_count, visible):\n",
    "    for i in range(layers_count):\n",
    "        visible = append_ones(dbn[i].visible_act_func(visible @ dbn[i].W[:, :-1]))\n",
    "    return visible\n",
    "\n",
    "def propagate_down(dbn, layers_count, hidden):\n",
    "    for i in reversed(range(layers_count)):\n",
    "        hidden = append_ones(dbn[i].hidden_act_func(hidden @ np.transpose(dbn[i].W[:-1, :])))\n",
    "    return hidden\n",
    "\n",
    "def dbn_reconstuction_error(dbn, layer_idx, minibatch):\n",
    "    propagated = propagate_up(dbn, layer_idx, minibatch)\n",
    "    error = reconstuction_error(dbn[layer_idx], propagated)\n",
    "    return error\n",
    "\n",
    "def train_dbn_layer(dbn, layer_idx, dataset, batch_size):\n",
    "    dataset = propagate_up(dbn, layer_idx, dataset)\n",
    "    \n",
    "    batches_limit = dataset.shape[0] / batch_size\n",
    "    for batch_idx, batch in enumerate(chunks(dataset, batch_size)):\n",
    "        cdk(dbn[layer_idx], batch)\n",
    "        if batch_idx % round(batches_limit / 40) == 0: print(\"#\", end=\"\")\n",
    "\n",
    "def train_dbn(dbn, dataset, monitoring_set, batch_size, epochs_count):\n",
    "    for layer_idx in range(len(dbn)):\n",
    "        print(\"\\nLearning layer {}\".format(layer_idx))\n",
    "        \n",
    "        for epoch in range(epochs_count):\n",
    "            print(\"Epoch {}:\".format(epoch+1),  end=\"\\t\")\n",
    "\n",
    "            if epoch == 5:\n",
    "                dbn[layer_idx].momentum = 0.9\n",
    "\n",
    "            start_time = time.time()\n",
    "            train_dbn_layer(dbn, layer_idx, dataset, batch_size)\n",
    "            elapsed = time.time() - start_time\n",
    "\n",
    "            error = dbn_reconstuction_error(dbn, layer_idx, monitoring_set)\n",
    "            print(\"\\telapsed: {0:>2.2f}s, reconstruction error: {1:>2.2f}\".format(elapsed, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, visible_size, hidden_size, activation_fun, d_activation_fun, \n",
    "                 learning_rate, momentum, l2_penalty):\n",
    "        self.visible_size = visible_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.activation_fun = activation_fun\n",
    "        self.d_activation_fun = d_activation_fun\n",
    "                \n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.l2_penalty = l2_penalty\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.W = np.random.normal(scale=0.01, size=(self.visible_size+1, self.hidden_size)).astype(np.float32)\n",
    "        self.W[-1, :] = 0.0\n",
    "        \n",
    "        self.activations = None\n",
    "        self.d_activations = None\n",
    "        self.deltas = None\n",
    "\n",
    "        self.M = zeros(self.visible_size+1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_pass(ae, batch, compute_derivatives):\n",
    "    visible = batch\n",
    "    \n",
    "    for layer_idx, layer in enumerate(ae):\n",
    "        z = visible @ layer.W\n",
    "        layer.activations = append_ones(layer.activation_fun(z))\n",
    "        \n",
    "        if compute_derivatives and (layer_idx < len(ae) - 1):\n",
    "            layer.d_activations = layer.d_activation_fun(z)\n",
    "            \n",
    "        visible = layer.activations\n",
    "\n",
    "    return visible[:, :-1]\n",
    "\n",
    "def error_backpropagate(ae, batch):\n",
    "    observations_count = batch.shape[0]\n",
    "\n",
    "    for layer_idx, layer in reversed(list(enumerate(ae))):\n",
    "        if layer_idx > 0:\n",
    "            prev_layer = ae[layer_idx - 1]\n",
    "            visible = prev_layer.activations\n",
    "            \n",
    "            prev_layer.deltas = (layer.deltas @ layer.W[:-1, :].T) * prev_layer.d_activations\n",
    "        else:\n",
    "            visible = batch\n",
    "        \n",
    "        layer.M *= layer.momentum\n",
    "        layer.M -= (layer.learning_rate / observations_count) * (visible.T @ layer.deltas)\n",
    "        \n",
    "        if layer.l2_penalty > 0:\n",
    "            layer.M[:-1, :] = layer.M[:-1, :] - layer.learning_rate * layer.l2_penalty * layer.W[:-1, :]\n",
    "        \n",
    "        layer.W += layer.M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entropy cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement cross entropy cost for deep AE. To this end:\n",
    "* calculate the cross entropy cost between pixels in the input batch and their reconstructions,\n",
    "* sum the cross entropy cost over all pixels and all observations in the minibatch,\n",
    "* return average cost per input observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xentropy(batch, reconstructions):\n",
    "    observations_count = batch.shape[0]\n",
    "    \n",
    "    raise Exception(\"Cross entropy cost is not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_ae(ae, dataset, batch_size):\n",
    "    batches_limit = dataset.shape[0] / batch_size\n",
    "    batched_data = chunks(dataset, batch_size)\n",
    "    \n",
    "    for batch_idx, batch in enumerate(batched_data):\n",
    "        reconstructions = forward_pass(ae, batch, True)\n",
    "\n",
    "        raise Exception(\"Gradient of the cross entropy cost wrt the deep AE output is not implemented\")\n",
    "        # ae[-1].deltas = ???\n",
    "        \n",
    "        error_backpropagate(ae, batch)\n",
    "        \n",
    "        if batch_idx % round(batches_limit / 40) == 0: print(\"#\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_ae_training(ae, train_set, validation_set, batch_size, epochs_count):\n",
    "    for epoch in range(epochs_count):\n",
    "        print(\"Epoch {}:\".format(epoch+1),  end=\"\\t\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        train_ae(ae, train_set, batch_size)\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        xe = xentropy(validation_set[:, :-1], forward_pass(ae, validation_set, False))\n",
    "        print(\"\\telapsed: {0:>2.2f}s, cross-entropy: {1:>2.2f}\".format(elapsed, xe))\n",
    "\n",
    "    print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Initializing AE with DBN weights\n",
    "\n",
    "Implement initialization of AE weights (and biases) using weights (and biases) from the DBN layers.\n",
    "\n",
    "Make sure that the AE weights (and biases) are **copies** of the DBN weights (and biases). You can use ```np.copy(...)``` function to copy the weights (simple assignment will make a view instead of a copy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_ae(ae, dbn):\n",
    "    assert(len(ae) == 2*len(dbn))\n",
    "    \n",
    "    raise Exception(\"Initialization of a deep AE is not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder for MNIST digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_SIZE = 10000 # 60000 for whole dataset\n",
    "DIGIT_SIZE = 28\n",
    "\n",
    "##### Train set #####\n",
    "\n",
    "mnist_train_images = mnist.train_images().astype(np.float32) / 255.0\n",
    "mnist_train_images = np.random.permutation(mnist_train_images)\n",
    "\n",
    "mnist_train_images = np.reshape(mnist_train_images[:DATASET_SIZE],\n",
    "                                newshape=(DATASET_SIZE, DIGIT_SIZE*DIGIT_SIZE))\n",
    "mnist_train_images = append_ones(mnist_train_images)\n",
    "\n",
    "monitoring_set_indeces = np.random.choice(mnist_train_images.shape[0], 512, replace=False)\n",
    "monitoring_set = mnist_train_images[monitoring_set_indeces]\n",
    "\n",
    "##### Test set #####\n",
    "\n",
    "mnist_test_images = mnist.test_images().astype(np.float32) / 255.0\n",
    "mnist_test_images = np.reshape(mnist_test_images, newshape=(-1, DIGIT_SIZE*DIGIT_SIZE))\n",
    "mnist_test_images = append_ones(mnist_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VISIBLE_LAYER_SIZE = DIGIT_SIZE*DIGIT_SIZE\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS_COUNT = 50\n",
    "\n",
    "RBM_LEARNING_RATE = 0.1\n",
    "AE_LEARNING_RATE = 0.01\n",
    "AE_MOMENTUM = 0.9\n",
    "L2_PENALTY = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def compare_results(ae, dbn,\n",
    "                    train_set, validation_set, monitoring_set,\n",
    "                    batch_size, epochs_count):\n",
    "    for layer in ae:\n",
    "        layer.reset()\n",
    "    \n",
    "    display(HTML('<h3>Plain AE training</h3>'))\n",
    "    run_ae_training(ae, train_set, validation_set,\n",
    "                    batch_size, epochs_count)\n",
    "    \n",
    "    display(HTML('<h3>Input layer filters in the plain AE</h3>'))\n",
    "    draw_layer_filters(ae[0])\n",
    "    \n",
    "    display(HTML('<h3>Input minibatch</h3>'))\n",
    "    tiles(np.reshape(validation_set[:8*24, :-1],\n",
    "                     newshape=(8, 24, 28, 28)))\n",
    "    \n",
    "    display(HTML('<h3>Plain AE reconstructions</h3>'))\n",
    "    ae_reconstructions = np.reshape(forward_pass(ae, validation_set[:8*24], False),\n",
    "                                    newshape=(8, 24, 28, 28))\n",
    "    tiles(ae_reconstructions)\n",
    "    \n",
    "    display(HTML('<h3>DBN training</h3>'))\n",
    "    train_dbn(dbn, train_set, monitoring_set, batch_size, epochs_count)\n",
    "    \n",
    "    for layer in ae:\n",
    "        layer.reset()\n",
    "    \n",
    "    initialize_ae(ae, dbn)\n",
    "    dbn_reconstructions = np.reshape(forward_pass(ae, validation_set[:8*24, :], False),\n",
    "                                     newshape=(8, 24, 28, 28))\n",
    "    dbn_rec_cost = xentropy(validation_set[:, :-1],\n",
    "                            forward_pass(ae, validation_set, False))\n",
    "    \n",
    "    display(HTML('<h3>Finetuning pretrained AE</h3>'))\n",
    "    \n",
    "    print(\"Reconstruction cost before finetuning: {0:>2.2f}\\n\".format(dbn_rec_cost))\n",
    "    run_ae_training(ae, train_set, validation_set,\n",
    "                    batch_size, epochs_count)\n",
    "    \n",
    "    display(HTML('<h3>First layer filters in the DBN</h3>'))\n",
    "    draw_rbm_filters(dbn[0])\n",
    "    \n",
    "    display(HTML('<h3>Input layer filters in the pretrained & finetuned AE</h3>'))\n",
    "    draw_layer_filters(ae[0])\n",
    "    \n",
    "    display(HTML('<h3>Input minibatch</h3>'))\n",
    "    tiles(np.reshape(validation_set[:8*24, :-1],\n",
    "                     newshape=(8, 24, 28, 28)))\n",
    "    \n",
    "    display(HTML('<h3>Pretrained AE reconstructions</h3>'))\n",
    "    tiles(dbn_reconstructions)\n",
    "    \n",
    "    display(HTML('<h3>Finetuned AE reconstructions</h3>'))\n",
    "    ae_reconstructions = np.reshape(forward_pass(ae, validation_set[:8*24], False),\n",
    "                                    newshape=(8, 24, 28, 28))\n",
    "    tiles(ae_reconstructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Autoencoder network\n",
    "\n",
    "Define the autoencoder network for MNIST digits. The network structure should be suitable for pretraining with the provided DBN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dbn = [\n",
    "    Rbm(VISIBLE_LAYER_SIZE, 256, sigmoid, sigmoid, RBM_LEARNING_RATE, 0.5, L2_PENALTY),\n",
    "    Rbm(256, 128, sigmoid, sigmoid, RBM_LEARNING_RATE, 0.5, L2_PENALTY),\n",
    "    Rbm(128, 64, sigmoid, sigmoid, RBM_LEARNING_RATE, 0.5, L2_PENALTY),\n",
    "    Rbm(64, 10, sigmoid, gaussian, RBM_LEARNING_RATE / 10.0, 0.5, L2_PENALTY)\n",
    "]\n",
    "\n",
    "\n",
    "raise Exception(\"AE structure is undefined!\")\n",
    "ae =  []\n",
    "\n",
    "compare_results(ae, dbn,\n",
    "                mnist_train_images, mnist_test_images,\n",
    "                monitoring_set,\n",
    "                BATCH_SIZE, EPOCHS_COUNT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
